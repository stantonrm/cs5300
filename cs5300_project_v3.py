# -*- coding: utf-8 -*-
"""cs5300_project_v3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1smEU2I-hWoSUbZLqJxSY6kFgWUYobIsW

# CS5300 Project Version 3: Added Genres

Only movies from USA are considered.
"""

from keras.models import Sequential
from keras.layers import Dense
import numpy as np
import matplotlib.pyplot as plt

from google.colab import files
uploaded = files.upload()

import numpy as np
dataset = np.loadtxt('movie_metadata_super_clean_usa_v3_4.csv', skiprows = 1,  delimiter=',')
np.random.shuffle(dataset)
dataset_features = 22

print('')
print(dataset.shape)
print('')
print(dataset[0:dataset_features + 1])

print(np.max(dataset[:, dataset_features]))
print(np.min(dataset[:, dataset_features]))

"""# Split data set into training and validation sets"""

trainset = dataset[:1800]
validset = dataset[1800:]
print(trainset.shape)
print('')
print(validset.shape)

plt.figure(figsize=(4,4))
plt.plot(trainset[:, 0], trainset[:, dataset_features], '.')
plt.xlabel('1st feature - budget')
plt.ylabel('gross revenue')
plt.show()

plt.figure(figsize=(4,4))
plt.plot(trainset[:, 1], trainset[:, dataset_features], '.')
plt.xlabel('2nd feature - Rating')
plt.ylabel('gross revenue')
plt.show()

plt.figure(figsize=(4,4))
plt.plot(trainset[:, 2], trainset[:, dataset_features], '.')
plt.xlabel('3nd feature - Duration')
plt.ylabel('gross revenue')
plt.show()

plt.figure(figsize=(4,4))
plt.plot(trainset[:, dataset_features - 1], trainset[:, dataset_features], '.')
plt.xlabel('Last feature - Western Genre')
plt.ylabel('gross revenue')
plt.show()

"""# **Separate Sets into Input and Output Sets**"""

trainset_input = trainset[:, 0:dataset_features]
trainset_output = trainset[:, dataset_features:]
validset_input = validset[:, 0:dataset_features]
validset_output = validset[:, dataset_features:]
print(trainset_input.shape)
print(trainset_output.shape)
print(validset_input.shape)
print(validset_output.shape)

"""# *Supposed to be a normalization step here.  I GET NAN WITHOUT THIS STEP*"""

mean = trainset_input.mean(axis=0)
trainset_input -= mean
std = trainset_input.std(axis=0)
trainset_input /= std

validset_input -= mean
validset_input /= std

"""# Build a model"""

model = Sequential()
model.add(Dense(1, input_dim = dataset_features, activation='linear'))
print(model.summary())
model.compile(loss='mse', optimizer='sgd', metrics=['mae'])
# Verbose = 0 shows no updates, can be changed to 1 or 2
history = model.fit(trainset_input, trainset_output, epochs= 128, verbose = 0, batch_size=8, validation_data = (validset_input, validset_output))

"""# Evaluate the predictions"""

prediction = model.predict(validset_input)
print(validset_output[0:5])
print('')
print(prediction[0:5])

plt.figure(figsize=(4,4))
plt.plot(prediction, validset_output, '.')
plt.xlabel('Predictions')
plt.ylabel('Correct values')
plt.show()

results = model.evaluate(validset_input, validset_output)
print ('mae = ', results[1])

"""## Let's design a bigger and more powerful model (NEED HELP WITH THIS)"""

model = Sequential()
model.add(Dense(16, input_dim = dataset_features, activation='sigmoid'))
model.add(Dense(1, activation='linear'))
print(model.summary())
model.compile(loss='mse', optimizer='sgd', metrics=['mae'])
# Verbose = 0 shows no updates, can be changed to 1 or 2
history = model.fit(trainset_input, trainset_output, epochs= 64, verbose = 0, batch_size=32, validation_data = (validset_input, validset_output))

prediction = model.predict(validset_input)
print(validset_output[0:5])
print('')
print(prediction[0:5])

plt.figure(figsize=(4,4))
plt.plot(prediction, validset_output, '.')
plt.xlabel('Predictions')
plt.ylabel('Correct values')
plt.show()

results = model.evaluate(validset_input, validset_output)
print ('mae = ', results[1])